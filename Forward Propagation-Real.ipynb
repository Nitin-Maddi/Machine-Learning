{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create a NeuralNetwork class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, dims):\n",
    "        \"\"\" create an object which takes in a list of layer sizes and creates\n",
    "        a list of weight matrices and a list of bias vectors, initialized to zeros. \"\"\"\n",
    "        self.layers = []\n",
    "        self.bias_layers = []\n",
    "        self.dims = dims\n",
    "        for i in range(len(dims)-1):\n",
    "            self.layers.append(np.zeros((dims[i], dims[i+1])))\n",
    "            self.bias_layers.append(np.zeros(dims[i+1]))\n",
    "        \n",
    "    def randomize_weights(self, min1=-1, max1=1):\n",
    "        self.layers = []\n",
    "        self.bias_layers = []\n",
    "        for i in range(len(self.dims)-1):\n",
    "            self.layers.append(np.random.uniform(min1, max1, size = (self.dims[i], self.dims[i+1])))\n",
    "            self.bias_layers.append(np.random.uniform(min1, max1, size = (1, self.dims[i+1])))\n",
    "        \"\"\" store all random reals in the weight matrices and bias vectors, between min and max \"\"\"\n",
    "\n",
    "    def randomize_nice(self, min1=-10, max1=10):\n",
    "        \"\"\" store all random ints in the weight matrices and bias vectors, between min and max\"\"\"\n",
    "        self.layers = []\n",
    "        self.bias_layers = []\n",
    "        for i in range(len(self.dims)-1):\n",
    "            self.layers.append(np.random.randint(size = (self.dims[i], self.dims[i+1]), low = min1, high = max1))\n",
    "            self.bias_layers.append(np.random.randint(size = (1, self.dims[i+1]), low = min1, high = max1))\n",
    "        \n",
    "    def print_layers(self):\n",
    "        for i in range(len(self.layers)):\n",
    "            print(\"layer\")\n",
    "            print(self.layers[i])\n",
    "            print(\"bias\")\n",
    "            print(self.bias_layers[i])\n",
    "        \"\"\" print contents of each weight matrix and bias vector \"\"\"\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quick check of initializer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "bias\n",
      "[0. 0. 0. 0. 0.]\n",
      "layer\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "bias\n",
      "[0. 0. 0.]\n",
      "layer\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "bias\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork([2,5,3,2])\n",
    "nn.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer\n",
      "[[-10  20 -20  50  30]\n",
      " [ 30 -20  10 -40 -20]]\n",
      "bias\n",
      "[[ 30  20 -10  20  30]]\n",
      "layer\n",
      "[[1 0 1]\n",
      " [0 0 1]\n",
      " [1 1 0]\n",
      " [0 1 0]\n",
      " [1 0 1]]\n",
      "bias\n",
      "[[ 20 -10 -10]]\n",
      "layer\n",
      "[[ 10   0]\n",
      " [-10  20]\n",
      " [-30   0]]\n",
      "bias\n",
      "[[-5  5]]\n"
     ]
    }
   ],
   "source": [
    "nn.layers[0] = np.array([[-10,20,-20,50,30],[30,-20,10,-40,-20]])\n",
    "nn.bias_layers[0] = np.array([[30,20,-10,20,30]])\n",
    "nn.layers[1] = np.array([[1,0,1],[0,0,1],[1,1,0],[0,1,0],[1,0,1]])\n",
    "nn.bias_layers[1] = np.array([[20,-10,-10]])\n",
    "nn.layers[2] = np.array([[10,0],[-10,20],[-30,0]])\n",
    "nn.bias_layers[2] = np.array([[-5,5]])\n",
    "nn.print_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Define sigmoid(x,k) with k default value=1 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x,k=1):\n",
    "    if x < -500:\n",
    "        return 0\n",
    "    return 1/(1+math.exp(-k*x))\n",
    "    \n",
    "def sigmoid_prime(x,k=1):\n",
    "    return (sigmoid(x) * (1-sigmoid(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Define step(x) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    if x > 0: return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tenth(x):\n",
    "    return x/10\n",
    "def tenth_der(x):\n",
    "    return 1/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define forward_propagate(NN, x, A, verbose)**\n",
    "  * This returns the (vector) output of feeding input vector \"x\" into Neural Net NN, with activation function A.\n",
    "  * The 'verbose' flag tells whether to print the output of each layer. Default is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(NN, x, A, verbose = False):\n",
    "    vector_A = np.vectorize(A)\n",
    "    for i in range(len(NN.layers)):\n",
    "        x = np.array(x)\n",
    "        x = vector_A(np.dot(x, NN.layers[i]) + NN.bias_layers[i])\n",
    "    if verbose == True:\n",
    "        print(x)\n",
    "        \n",
    "    \n",
    "    return x\n",
    "        \n",
    "        \n",
    "    \"\"\" given neural net NN and input vector x, and activation function A,\n",
    "    return the output of the final layer of the NN. If verbose if true,\n",
    "    print output of each layer along the way\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the following outputs against your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Set the numpy random seed to 101. Create a 2,4,2,5,2 Neural Network. Randomize its weights integers between -10 and 10 and print the layers **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer\n",
      "[[ 1  7 -4  1]\n",
      " [ 5 -1  3 -2]]\n",
      "bias\n",
      "[[ -6  -2 -10   4]]\n",
      "layer\n",
      "[[-5  2]\n",
      " [-2  7]\n",
      " [ 9  5]\n",
      " [-2  9]]\n",
      "bias\n",
      "[[ 9 -8]]\n",
      "layer\n",
      "[[  2  -2   9   0   2]\n",
      " [  1 -10  -1  -1   5]]\n",
      "bias\n",
      "[[-2 -6  9 -7 -3]]\n",
      "layer\n",
      "[[ 0 -3]\n",
      " [-4  4]\n",
      " [-1  8]\n",
      " [-3 -3]\n",
      " [ 5  2]]\n",
      "bias\n",
      "[[-10   0]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(101)\n",
    "nn = NeuralNetwork([2,4,2,5,2])\n",
    "nn.randomize_nice()\n",
    "nn.print_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Define an input vector [10,20] and propagate it through the NN above. Show the output of each layer. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x = [10,20]\n",
    "\n",
    "forward_propagate(nn,x,tenth,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7964 -2.7548]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.7964, -2.7548]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[10,20]\n",
    "forward_propagate(nn,x,tenth,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagate(NN, x, y, A, A_prime):\n",
    "        outputs = []\n",
    "        lamb = 100\n",
    "        outputs.append(np.array(x))\n",
    "        for i in range(len(NN.layers)): #Forward Propagation\n",
    "            x = np.array(x)\n",
    "            x = A(np.dot(x, NN.layers[i]) + NN.bias_layers[i])\n",
    "            outputs.append(x)\n",
    "        print(outputs)\n",
    "        grad = (A_prime(1) * (y-x)) # Calculate error for final output\n",
    "        grad_matrix = []\n",
    "        grad_matrix.append(np.array(grad))\n",
    "        for i in range(len(NN.layers)-1,0,-1):  # Calculates the rest of the gradients \n",
    "            arr = []\n",
    "            for j in range(len(NN.layers[i])):\n",
    "                arr.append(A_prime(1) * grad_matrix[i - len(NN.layers) + 1] @ NN.layers[i][j])\n",
    "            grad_matrix.append(np.array(arr))\n",
    "            print((grad_matrix[0],NN.layers[i]))\n",
    "        print(grad_matrix)\n",
    "        for i in range(len(NN.layers)):  #Update all of the other weights using gradient\n",
    "            for j in range(len(NN.layers[i])):\n",
    "                NN.layers[i][j] = NN.layers[i][j] + outputs[i][j] * lamb * grad_matrix[len(NN.layers)-i-1]\n",
    "        NN.print_layers()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer\n",
      "[[4, -2], [0, 1], [2, 6]]\n",
      "bias\n",
      "[0. 0.]\n",
      "layer\n",
      "[[2, 3], [3, 2]]\n",
      "bias\n",
      "[0. 0.]\n",
      "[array([10, 20, 30]), array([10., 18.]), array([7.4, 6.6])]\n",
      "(array([ 0.06, -0.06]), [[2, 3], [3, 2]])\n",
      "[array([ 0.06, -0.06]), array([-0.006,  0.006])]\n",
      "layer\n",
      "[array([-2.,  4.]), array([-12.,  13.]), array([-16.,  24.])]\n",
      "bias\n",
      "[0. 0.]\n",
      "layer\n",
      "[array([ 62., -57.]), array([ 111., -106.])]\n",
      "bias\n",
      "[0. 0.]\n",
      "-0.06\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork([3,2,2])\n",
    "nn.layers[0] = [[4,-2], [0,1], [2,6]]\n",
    "nn.layers[1] = [[2,3],[3,2]]\n",
    "nn.print_layers()\n",
    "back_propagate(nn, [10,20,30], [8,6], tenth, tenth_der)\n",
    "b = np.array([.03,0]) @ np.array([-2,-1])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagate_matrix(NN, training_set, A, A_prime):\n",
    "    epochs = 2000\n",
    "    lamb = 1\n",
    "    count = 1\n",
    "    NN.randomize_weights()\n",
    "    vector_A_prime = np.vectorize(A_prime)\n",
    "    vector_A = np.vectorize(A)\n",
    "    for e in range(epochs):\n",
    "        for tup in training_set:\n",
    "            x, y = tup\n",
    "            outputs = []\n",
    "            dots = []\n",
    "            x = np.array([x])\n",
    "            outputs.append(x)\n",
    "            dots.append(x)\n",
    "            for i in range(len(NN.layers)): #Forward Propagation\n",
    "                dot = np.dot(x, NN.layers[i]) + NN.bias_layers[i]\n",
    "                x = vector_A(dot)\n",
    "                dots.append(dot)\n",
    "                outputs.append(x)\n",
    "            error = y-x\n",
    "            delta = (vector_A_prime(outputs[-1]) * (y-x)) # Calculate error for final output\n",
    "            delta_matrix = []\n",
    "            delta_matrix.append(delta)\n",
    "            for i in range(len(NN.layers)-1,0,-1):  # Calculates the rest of the gradients\n",
    "                delta_matrix.append(np.multiply(vector_A_prime(dots[i]), np.matmul(delta_matrix[i - len(NN.layers) + 1], np.transpose(NN.layers[i]))))\n",
    "            for i in range(len(NN.layers)):  #Update all of the other weights using gradient\n",
    "                NN.layers[i] = NN.layers[i] + (np.transpose(outputs[i])) *  delta_matrix[len(NN.layers)-i-1] *  lamb\n",
    "                NN.bias_layers[i] = NN.bias_layers[i] + lamb * delta_matrix[len(NN.layers)-i-1]\n",
    "            count += 1\n",
    "            if count % 500 == 0:\n",
    "                print(count)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for tup in training_set:\n",
    "        x,y = tup\n",
    "        out = forward_propagate(NN,x, sigmoid, verbose = True)\n",
    "        if np.argmax(y) == np.argmax(x):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "[[0.00153353]]\n",
      "[[0.99505487]]\n",
      "[[0.99216954]]\n",
      "[[0.01124973]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNetwork([2,4,1])\n",
    "training_set = [(np.array([0,0]),np.array([0])), (np.array([0,1]),np.array([1])), (np.array([1,0]),np.array([1])),(np.array([1,1]),np.array([0]))]\n",
    "back_propagate_matrix(nn, training_set, sigmoid, sigmoid_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"mnist_train.csv\")\n",
    "test = pd.read_csv(\"mnist_test.csv\")\n",
    "rows, col = train.shape\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = []\n",
    "for i in range(rows):\n",
    "    row = train.iloc[i,:]\n",
    "    out = row.iloc[0]\n",
    "    encode = np.zeros((1,10))\n",
    "    encode[0][out] = 1\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    tup = (row.iloc[1:785],encode)\n",
    "    training_set.append(tup)\n",
    "test_set = []\n",
    "for i in range(test.shape[0]):\n",
    "    row = test.iloc[i,:]\n",
    "    out = row.iloc[0]\n",
    "    encode = np.zeros((1,10))\n",
    "    encode[0][out] = 1\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    tup = (row.iloc[1:785],encode)\n",
    "    test_set.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_propagate_matrix(nn, training_set, sigmoid, sigmoid_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
